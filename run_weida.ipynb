{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /\n",
      "['gzh', 'run.ipynb', 'Untitled-1.py', 'bert-base-uncased', 'All(1).xlsx', 'data.csv', 'run_.py', 'model', 'run.py', 'transformer.py', '__pycache__', 'run_weida.ipynb', 'TrafficLabelling']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append('/data')\n",
    "print(os.listdir('/data'))\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# LSTM \n",
    "from model.lstm import LSTM\n",
    "# GRU \n",
    "from model.gru import GRUModel\n",
    "# Neural Network \n",
    "from model.neural import NeuralODE\n",
    "# Transformer \n",
    "from transformer import TransformerModel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split  # 从 scikit-learn 的 model_selection 模块导入 split 方法用于分割训练集和测试集\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, classification_report\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -9.51999207e+02  1.63980881e+02 ...  1.70204810e+03\n",
      "   2.20064819e+03  2.57268018e+03]\n",
      " [ 1.00000000e+00  2.34012375e+02 -2.14050640e+01 ...  3.87370850e+02\n",
      "   9.42485413e+02  1.74413525e+03]\n",
      " [ 1.00000000e+00 -4.02055206e+02 -2.33310974e+02 ... -1.06804939e+02\n",
      "  -1.00123848e+02  5.98292240e+01]\n",
      " ...\n",
      " [ 1.00000000e+00 -3.54019897e+02  5.29676758e+02 ...  2.96929260e+02\n",
      "   5.66300476e+02  6.93430298e+02]\n",
      " [ 1.00000000e+00  1.69617661e+02 -3.17932251e+02 ... -3.45730469e+02\n",
      "  -1.03475870e+01  6.33245300e+02]\n",
      " [ 1.00000000e+00 -1.95822250e+02 -1.40486282e+02 ...  5.03955658e+02\n",
      "   3.67848328e+02 -1.95307693e+02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-951.999207  163.980881 1215.220215 ... 1702.048096 2200.648193\n",
      "  2572.680176]\n",
      " [ 234.012375  -21.405064  124.714081 ...  387.37085   942.485413\n",
      "  1744.135254]\n",
      " [-402.055206 -233.310974  -46.596706 ... -106.804939 -100.123848\n",
      "    59.829224]\n",
      " ...\n",
      " [-354.019897  529.676758 1538.847168 ...  296.92926   566.300476\n",
      "   693.430298]\n",
      " [ 169.617661 -317.932251 -572.153625 ... -345.730469  -10.347587\n",
      "   633.2453  ]\n",
      " [-195.82225  -140.486282  -57.452263 ...  503.955658  367.848328\n",
      "  -195.307693]]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/data/data.csv').values\n",
    "data =  np.random.permutation(data)\n",
    "print(data)\n",
    "plt.hist(data[:,0], edgecolor='black')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "X = data[:,1:]\n",
    "Y= data[:,0]\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_234049/1169129972.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
      "/tmp/ipykernel_234049/1169129972.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
      "/tmp/ipykernel_234049/1169129972.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
      "/tmp/ipykernel_234049/1169129972.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).long()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).long()\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        # 定义 Transformer 编码器，并指定输入维数和头数\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=1)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "        # 定义全连接层，将 Transformer 编码器的输出映射到分类空间\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 在序列的第2个维度（也就是时间步或帧）上添加一维以适应 Transformer 的输入格式\n",
    "        x = x.unsqueeze(1)\n",
    "        # 将输入数据流经 Transformer 编码器进行特征提取\n",
    "        x = self.encoder(x)\n",
    "        # 通过压缩第2个维度将编码器的输出恢复到原来的形状\n",
    "        x = x.squeeze(1)\n",
    "        # 将编码器的输出传入全连接层，获得最终的输出结果\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建模型\n"
     ]
    }
   ],
   "source": [
    "print(\"创建模型\")\n",
    "# 初始化 Transformer 模型\n",
    "\n",
    "model = TransformerModel(input_size=1015, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 定义损失函数和优化器\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# 定义损失函数和优化器\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# 存储训练过程中的损失值和召回率\n",
    "train_losses = []\n",
    "recall_scores = []\n",
    "\n",
    "accuracy_scores = []  # 初始化accuracy_scores\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "mse_scores = []\n",
    "\n",
    "print(\"训练模型\")\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # 前向传播计算输出结果\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    # 反向传播，更新梯度并优化模型参数\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 记录损失值\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # 每10个epoch计算召回率\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            # 计算各类指标\n",
    "            accuracy = accuracy_score(y_train, predicted)\n",
    "            recall = recall_score(y_train, predicted, average='macro')  # 宏平均\n",
    "            precision = precision_score(y_train, predicted, average='macro')  # 宏平均\n",
    "            f1 = f1_score(y_train, predicted, average='macro')  # 宏平均\n",
    "            mse = mean_squared_error(y_train, predicted)  # MSE\n",
    "\n",
    "            # 记录每个指标的值\n",
    "            accuracy_scores.append(accuracy)\n",
    "            recall_scores.append(recall)\n",
    "            precision_scores.append(precision)\n",
    "            f1_scores.append(f1)\n",
    "            mse_scores.append(mse)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, '\n",
    "              f'Recall: {recall:.4f}, Precision: {precision:.4f}, F1 Score: {f1:.4f}, MSE: {mse:.4f}')\n",
    "print(\"测试模型\")\n",
    "# 测试模型的评分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy: 1.0000, Recall: 1.0000, Precision: 1.0000, F1 Score: 1.0000, MSE: 0.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       255\n",
      "           1       1.00      1.00      1.00       508\n",
      "\n",
      "    accuracy                           1.00       763\n",
      "   macro avg       1.00      1.00      1.00       763\n",
      "weighted avg       1.00      1.00      1.00       763\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 绘制损失曲线\u001b[39;00m\n\u001b[1;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 21\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[43mnum_epochs\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), train_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_epochs' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    # 计算测试集的各类评估指标\n",
    "    print(predicted)\n",
    "    accuracy = accuracy_score(y_test, predicted)\n",
    "    recall = recall_score(y_test, predicted, average='macro')  # 宏平均\n",
    "    precision = precision_score(y_test, predicted, average='macro')  # 宏平均\n",
    "    f1 = f1_score(y_test, predicted, average='macro')  # 宏平均\n",
    "    mse = mean_squared_error(y_test, predicted)  # MSE\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, '\n",
    "          f'F1 Score: {f1:.4f}, MSE: {mse:.4f}')\n",
    "\n",
    "    # 输出分类报告，查看每个类别的性能\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predicted))\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制准确率曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(10, num_epochs + 1, 10), accuracy_scores, label='Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制召回率曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(10, num_epochs + 1, 10), recall_scores, label='Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.title('Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制精确率曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(10, num_epochs + 1, 10), precision_scores, label='Precision')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制 F1 分数曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(10, num_epochs + 1, 10), f1_scores, label='F1 Score')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制 MSE 曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(10, num_epochs + 1, 10), mse_scores, label='Mean Squared Error')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('Mean Squared Error Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_losses\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth')\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "outputs = model(X_test)\n",
    "#print(X_test)\n",
    "_, predicted = torch.max(outputs.data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " ...\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]]\n",
      "[[ 0.00000000e+00  0.00000000e+00  4.87183723e+01 ...  6.88594103e+00\n",
      "  -2.52977772e+01 -9.41139526e+01]\n",
      " [ 1.00000000e+00  1.00000000e+00 -7.74501282e+02 ...  7.11680908e+02\n",
      "   1.09216553e+03  1.44794666e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.21640656e+02 ...  2.51375565e+02\n",
      "   1.91022446e+02  4.50003853e+01]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00 -2.78263702e+02 ... -6.58242645e+01\n",
      "  -1.76734295e+01 -8.27314072e+01]\n",
      " [ 1.00000000e+00  1.00000000e+00 -2.48549271e+02 ...  9.08679932e+02\n",
      "   9.98085693e+02  8.37824036e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  7.16342316e+01 ...  7.39940977e+00\n",
      "   7.93778992e+00  8.06886196e+00]]\n",
      "两个数组中相同的元素个数: 3051\n",
      "Y_test 中值为 1 的个数: 1919\n",
      "预测成功的概率 (值为 1): 1.0000\n",
      "Y_test 中值为 0 的个数: 1132\n",
      "预测成功的概率 (值为 0): 1.0000\n"
     ]
    }
   ],
   "source": [
    "y_pre=model(X_train)\n",
    "X_train =X_train .detach().numpy()\n",
    "y_train = y_train.detach().numpy().reshape(len(y_train),-1)\n",
    "_, y_pre = torch.max(y_pre.data, 1)\n",
    "y_pre= y_pre.detach().numpy().reshape(len(y_pre),-1)\n",
    "#print(y_pre)\n",
    "\n",
    "train = np.hstack((y_train , y_pre))\n",
    "print(train)\n",
    "train= np.hstack((train,X_train))\n",
    "print(train)\n",
    "np.savetxt('./train.csv',train,delimiter=',')\n",
    "\n",
    "same_count = np.sum(y_pre == y_pre)\n",
    "print(f\"两个数组中相同的元素个数: {same_count}\")\n",
    "\n",
    "count_1 = np.sum(y_train == 1)  # 统计 Y_test 中值为 1 的数量\n",
    "correct_1 = np.sum((y_train == 1) & (y_pre == 1))  # 统计预测正确的数量\n",
    "probability_1 = correct_1 / count_1 if count_1 > 0 else 0  # 成功概率\n",
    "\n",
    "# Y_test 中值为 0 的个数和预测成功的概率\n",
    "count_0 = np.sum(y_train == 0)  # 统计 Y_test 中值为 0 的数量\n",
    "correct_0 = np.sum((y_train == 0) & (y_pre == 0))  # 统计预测正确的数量\n",
    "probability_0 = correct_0 / count_0 if count_0 > 0 else 0  # 成功概率\n",
    "# 输出结果\n",
    "print(f\"Y_test 中值为 1 的个数: {count_1}\")\n",
    "print(f\"预测成功的概率 (值为 1): {probability_1:.4f}\")\n",
    "print(f\"Y_test 中值为 0 的个数: {count_0}\")\n",
    "print(f\"预测成功的概率 (值为 0): {probability_0:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "两个数组中相同的元素个数: 763\n",
      "Y_test 中值为 1 的个数: 508\n",
      "预测成功的概率 (值为 1): 1.0000\n",
      "Y_test 中值为 0 的个数: 255\n",
      "预测成功的概率 (值为 0): 1.0000\n",
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "[[ 1.00000000e+00  1.00000000e+00 -1.71895798e+02 ...  7.67253906e+02\n",
      "   8.30733704e+02  7.05307556e+02]\n",
      " [ 1.00000000e+00  1.00000000e+00 -7.18406494e+02 ... -5.78841934e+01\n",
      "  -2.32721386e+01  9.75451736e+01]\n",
      " [ 1.00000000e+00  1.00000000e+00 -1.80709503e+02 ...  1.93450348e+02\n",
      "   2.35834305e+02  2.32357361e+02]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00 -1.40101456e+02 ...  2.76368713e+02\n",
      "   5.23851562e+02  7.21686707e+02]\n",
      " [ 1.00000000e+00  1.00000000e+00 -1.11896563e+01 ...  1.19528061e+02\n",
      "   2.96474731e+02  4.14792175e+02]\n",
      " [ 1.00000000e+00  1.00000000e+00 -3.98621002e+02 ...  7.03523254e+02\n",
      "   1.03256421e+03  1.32896069e+03]]\n",
      "[[ 1.00000000e+00  1.00000000e+00 -1.71895798e+02 ...  7.67253906e+02\n",
      "   8.30733704e+02  7.05307556e+02]\n",
      " [ 1.00000000e+00  1.00000000e+00 -7.18406494e+02 ... -5.78841934e+01\n",
      "  -2.32721386e+01  9.75451736e+01]\n",
      " [ 1.00000000e+00  1.00000000e+00 -1.80709503e+02 ...  1.93450348e+02\n",
      "   2.35834305e+02  2.32357361e+02]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00 -1.40101456e+02 ...  2.76368713e+02\n",
      "   5.23851562e+02  7.21686707e+02]\n",
      " [ 1.00000000e+00  1.00000000e+00 -1.11896563e+01 ...  1.19528061e+02\n",
      "   2.96474731e+02  4.14792175e+02]\n",
      " [ 1.00000000e+00  1.00000000e+00 -3.98621002e+02 ...  7.03523254e+02\n",
      "   1.03256421e+03  1.32896069e+03]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_test=y_test.detach().numpy().reshape(len(y_test),-1)\n",
    "\n",
    "predict_1 = predicted.detach().numpy().reshape(len(predicted),-1)\n",
    "print(predict_1)\n",
    "\n",
    "same_count = np.sum(Y_test == predict_1)\n",
    "print(f\"两个数组中相同的元素个数: {same_count}\")\n",
    "\n",
    "count_1 = np.sum(Y_test == 1)  # 统计 Y_test 中值为 1 的数量\n",
    "correct_1 = np.sum((Y_test == 1) & (predict_1 == 1))  # 统计预测正确的数量\n",
    "probability_1 = correct_1 / count_1 if count_1 > 0 else 0  # 成功概率\n",
    "\n",
    "# Y_test 中值为 0 的个数和预测成功的概率\n",
    "count_0 = np.sum(Y_test == 0)  # 统计 Y_test 中值为 0 的数量\n",
    "correct_0 = np.sum((Y_test == 0) & (predict_1 == 0))  # 统计预测正确的数量\n",
    "probability_0 = correct_0 / count_0 if count_0 > 0 else 0  # 成功概率\n",
    "# 输出结果\n",
    "print(f\"Y_test 中值为 1 的个数: {count_1}\")\n",
    "print(f\"预测成功的概率 (值为 1): {probability_1:.4f}\")\n",
    "print(f\"Y_test 中值为 0 的个数: {count_0}\")\n",
    "print(f\"预测成功的概率 (值为 0): {probability_0:.4f}\")\n",
    "\n",
    "train = np.hstack((Y_test , predict_1))\n",
    "print(train)\n",
    "X=X_test.detach().numpy().reshape(len(predict_1),-1)\n",
    "train= np.hstack((train,X))\n",
    "print(train)\n",
    "np.savetxt('./test.csv',train,delimiter=',')\n",
    "\n",
    "\n",
    "print(train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
